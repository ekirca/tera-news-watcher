# -*- coding: utf-8 -*-
"""
Tera News Watcher â€” Render iÃ§in sade ve temiz versiyon

- Google News RSS'ten anahtar kelimelere gÃ¶re haber Ã§eker
- Filtreler: tekrar, zaman, domain beyaz liste, Tera ÅŸirket eÅŸleÅŸmesi
- Yeni haberleri Telegram kanalÄ±na yollar
- /health ve /test endpointleri ile kontrol / test
"""

import os
import time
import threading
from datetime import datetime, timedelta
from urllib.parse import quote_plus, urlparse
import urllib
import xml.etree.ElementTree as ET
from email.utils import parsedate_to_datetime
import feedparser
import requests
from flask import Flask, jsonify, request
import schedule

# =========================
# Ortam deÄŸiÅŸkenleri / Ayar
# =========================

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "").strip()

# Haber tarama periyodu (dakika)
POLL_INTERVAL_MIN = int(os.getenv("POLL_INTERVAL_MIN", "10"))

# "Eski haber" eÅŸiÄŸi (UTC; varsayÄ±lan: son 72 saat)
MAX_AGE_HOURS = int(os.getenv("MAX_AGE_HOURS", "72"))

# Domain filtresini komple kapatmak iÃ§in True yap (debug iÃ§in)
DISABLE_DOMAIN_FILTER = False

# Hata bildirimi iÃ§in global durumlar
LAST_JOB_TIME = None          # job() en son ne zaman baÅŸarÄ±yla bitti
LAST_ERROR_TIME = None        # son hata bildirimi zamanÄ±
ERROR_COOLDOWN_MIN = 30       # aynÄ± tÃ¼r hatayÄ± en az kaÃ§ dakika arayla Telegram'a gÃ¶nderelim

# ----------------------------
# Anahtar kelimeler (Google News aramasÄ±)
# ----------------------------
KEYWORDS = [
    "tera",
    "tera yatÄ±rÄ±m",
    "tera yatirim",
    "tehol",
    "trhol",
    "tly",
    "tera ÅŸirketleri",
]

# ----------------------------
# Åirket isimleri (eÅŸleÅŸme iÃ§in)
# ----------------------------
COMPANY_TOKENS = [
    # Holding / ana ÅŸirket
    "tera yatÄ±rÄ±m",
    "tera yatÄ±rÄ±m menkul deÄŸerler",
    "tera yatÄ±rÄ±m menkul degerler",
    "tera yatÄ±rÄ±m menkul deÄŸerler a.ÅŸ",
    "tera yatÄ±rÄ±m menkul degerler a.s",

    # Finans
    "tera bank",
    "tera finans faktoring",
    "tera portfÃ¶y",
    "tera giriÅŸim sermayesi",
    "kointra",
    "tera finansal yatÄ±rÄ±mlar holding",

    # Teknoloji
    "tera yatÄ±rÄ±m teknoloji holding",
    "barikat grup",
    "barikat",
    "tra biliÅŸim",
    "tra bilisim",

    # TarÄ±m / Su
    "viva terra hayvancÄ±lÄ±k",
    "viva terra su",

    # Hizmet
    "tera Ã¶zel gÃ¼venlik",

    # Fon / Ã¼rÃ¼n
    "tly fonu",
    "tera ly",
    "tera ly fonu",
]

# Åirket eÅŸleÅŸmesini biraz daha agresif yapmak iÃ§in Ã§ekirdek anahtarlar
BASE_KEYWORDS = [
    "tera",
    "tera yatirim",
    "tera yatÄ±rÄ±m",
    "tera yatÄ±rÄ±m menkul",
    "tera yatÄ±rÄ±m menkul deÄŸerler",
    "tera yatÄ±rÄ±m teknoloji holding",
    "tera finansal yatÄ±rÄ±mlar holding",
    "barikat",
    "tra bilisim",
    "tra biliÅŸim",
    "viva terra",
]

# ----------------------------
# Domain beyaz liste
# ----------------------------
ALLOWED_DOMAINS = [
    # BÃ¼yÃ¼k haber portallarÄ±
    "hurriyet.com.tr",
    "milliyet.com.tr",
    "cnnturk.com",
    "ntv.com.tr",
    "bbc.com",
    "reuters.com",
    "bloomberg.com",
    "bloomberght.com",
    "aa.com.tr",
    "trthaber.com",
    "aljazeera.com",

    # Ekonomi / Finans
    "dunya.com",
    "ekonomim.com",
    "foreks.com",
    "investing.com",
    "ekoturk.com",
    "haberturk.com",
    "sozcu.com.tr",
    "sabah.com.tr",
    "t24.com.tr",
    "patronlardunyasi.com",
    "borsagundem.com.tr",
    "finansgundem.com",
    "bigpara.hurriyet.com.tr",
    "tr.investing.com",
    "terayatirim.com",
    "terayatirim.com.tr",
    "x.com",
    "twitter.com",
    "nitter.net",


    # Resmi / kurumsal
    "kap.org.tr",
    "kamuyuaydinlatma.com",
]

# =========================
# Dosyalar
# =========================

SEEN_FILE = "seen_ids.txt"
INIT_FILE = ".initialized"
MAX_SEEN_IDS = 50000  # 50 bin id'den fazlasÄ±nÄ± tutma (Ã§ok fazlasÄ± gereksiz)


# =========================
# YardÄ±mcÄ± fonksiyonlar
# =========================

def debug_print(*args):
    """Basit log helper (anÄ±nda flush)."""
    print(*args, flush=True)


def normalize_text(txt: str) -> str:
    """
    TÃ¼rkÃ§e karakterleri sadeleÅŸtirip kÃ¼Ã§Ã¼k harfe Ã§evirir.
    BÃ¶ylece 'yatÄ±rÄ±m / yatirim / YATIRIM' hepsi aynÄ± hale gelir.
    """
    table = str.maketrans(
        "Ã‡Ã§ÄÄŸÄ°IÄ±Ã–Ã¶ÅÅŸÃœÃ¼",
        "ccggiiioossuu"
    )
    return txt.translate(table).lower()


def domain_allowed(link: str) -> bool:
    """Link'in domaini beyaz listedeyse True dÃ¶ndÃ¼rÃ¼r."""
    if DISABLE_DOMAIN_FILTER:
        return True
    try:
        netloc = urlparse(link).netloc.lower()
        if netloc.startswith("www."):
            netloc = netloc[4:]
        for d in ALLOWED_DOMAINS:
            if netloc.endswith(d):
                return True
        return False
    except Exception:
        return False

def process_extra_sources(cutoff_time, seen):
    """config.yamlâ€™daki 'sources' listesinden gelen Ã¶ÄŸeleri iÅŸler.
       - zaman filtresi (cutoff_time)
       - domain filtresi
       - tekrarÄ± Ã¶nleme (seen)
       - Telegramâ€™a gÃ¶nderim
    """
    new_count = 0
    try:
        extras = gather_extra_sources()
    except Exception as e:
        notify_error(f"extra sources fetch error: {e}")
        return 0

    for it in extras:
        title = (it.get("title") or "").strip()
        url   = (it.get("url")   or "").strip()
        pubts = it.get("published")  # epoch saniye (veya None)
        src   = it.get("source") or "extra"

        # ID: url + timestamp kombinasyonu
        iid = f"{url}|{int(pubts or 0)}"
        if iid in seen:
            continue

        # zaman filtresi
        if pubts:
            try:
                dt = datetime.utcfromtimestamp(pubts)
                if dt < cutoff_time:
                    continue
            except Exception:
                pass  # tarih yoksa geÃ§

        # domain filtresi
        if not domain_allowed(url):
            continue

        # Telegram
        msg = f"ğŸ§© <b>{src}</b>\n{title}\n{url}"
        send_telegram(msg)

        seen.add(iid)
        new_count += 1

    return new_count


def matches_company(it: dict) -> bool:
    """
    BaÅŸlÄ±k + aÃ§Ä±klama iÃ§inde Tera ile iliÅŸkili ÅŸirket adlarÄ± var mÄ±?
    TÃ¼rkÃ§e karakterler normalize edilerek karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
    """
    text = normalize_text((it.get("title", "") + " " + it.get("desc", "")))

    tokens = [normalize_text(k) for k in (COMPANY_TOKENS + BASE_KEYWORDS)]

    return any(k in text for k in tokens)


def send_telegram(text: str) -> None:
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        debug_print("âš ï¸ TELEGRAM_BOT_TOKEN veya TELEGRAM_CHAT_ID yok, mesaj gÃ¶nderilmedi.")
        return

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    data = {"chat_id": TELEGRAM_CHAT_ID, "text": text, "parse_mode": "HTML"}
    try:
        r = requests.post(url, data=data, timeout=15)
        debug_print("Telegram gÃ¶nderildi:", r.status_code)
    except Exception as e:
        debug_print("Telegram hata:", e)


def notify_error(message: str):
    """Hata durumunda hem log'a yaz, hem de Telegram'a makul sÄ±klÄ±kta uyarÄ± gÃ¶nder."""
    global LAST_ERROR_TIME
    now = datetime.utcnow()

    if LAST_ERROR_TIME is None or (now - LAST_ERROR_TIME).total_seconds() > ERROR_COOLDOWN_MIN * 60:
        try:
            send_telegram(f"âš ï¸ Hata uyarÄ±sÄ±:\n{message}")
            LAST_ERROR_TIME = now
        except Exception as e:
            print("notify_error iÃ§inde hata:", e)

    print("ERROR:", message)


def google_news_rss(query: str) -> str:
    """Google News RSS URL'ini Ã§aÄŸÄ±rÄ±r ve XML dÃ¶ndÃ¼rÃ¼r."""
    q = quote_plus(query + " site:tr OR site:.com OR site:.com.tr")
    u = f"https://news.google.com/rss/search?q={q}&hl=tr&gl=TR&ceid=TR:tr"
    r = requests.get(u, timeout=30)
    r.raise_for_status()
    return r.text


def parse_rss(xml_text: str):
    """RSS'i parse edip {id,title,link,pub,pub_dt,desc} listesi dÃ¶ndÃ¼rÃ¼r."""
    root = ET.fromstring(xml_text)
    items = []
    for it in root.findall(".//item"):
        title = (it.findtext("title") or "").strip()
        link = (it.findtext("link") or "").strip()
        guid = (it.findtext("guid") or link or title).strip()
        pub = (it.findtext("pubDate") or "").strip()
        desc = (it.findtext("description") or "").strip()

        pub_dt = None
        if pub:
            try:
                dt = parsedate_to_datetime(pub)
                if dt.tzinfo is not None:
                    dt = dt.astimezone(tz=None).replace(tzinfo=None)
                pub_dt = dt
            except Exception:
                pub_dt = None

        items.append(
            {
                "id": guid or link or title,
                "title": title,
                "link": link,
                "pub": pub,
                "pub_dt": pub_dt,
                "desc": desc,
            }
        )
    return items


def load_seen():
    if not os.path.exists(SEEN_FILE):
        return set()
    with open(SEEN_FILE, "r", encoding="utf-8") as f:
        return set(l.strip() for l in f if l.strip())


def save_seen(seen: set):
    # Set sÄ±rasÄ±z, ama Ã§ok bÃ¼yÃ¼rse rastgele bazÄ± eski kayÄ±tlar uÃ§muÅŸ olur â€” problem deÄŸil.
    if len(seen) > MAX_SEEN_IDS:
        seen = set(list(seen)[:MAX_SEEN_IDS])

    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(seen))


# --- SEEN dosyasÄ±nÄ± artÄ±mlÄ± yazmak ve son MAX satÄ±rÄ± tutmak iÃ§in ---
def save_seen_incremental(added_ids):
    """Bu run'da bulunan yeni id'leri sona ekler, sonra dosyayÄ± son MAX satÄ±ra kÄ±rpar."""
    if not added_ids:
        return

    # 1) Sona ekle
    with open(SEEN_FILE, "a", encoding="utf-8") as f:
        for uid in added_ids:
            f.write(uid + "\n")

    # 2) Gerekirse dosyayÄ± son MAX satÄ±ra kÄ±rp
    try:
        with open(SEEN_FILE, "r", encoding="utf-8") as f:
            lines = [ln.strip() for ln in f if ln.strip()]
    except FileNotFoundError:
        return

    if len(lines) > MAX_SEEN_IDS:
        # Sadece SON MAX_SEEN_IDS satÄ±rÄ± tut (en tazeler)
        keep = lines[-MAX_SEEN_IDS:]
        with open(SEEN_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(keep))

def save_seen_overwrite(seen_set):
    """Bootstrap gibi 'tam yenileme' durumlarÄ± iÃ§in: sÄ±rayÄ± umursamadan komple yazar."""
    data = list(seen_set)
    if len(data) > MAX_SEEN_IDS:
        data = data[-MAX_SEEN_IDS:]  # burada sÄ±ra Ã¶nemsiz; bootstrap'ta bildirim de atmÄ±yoruz
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(data))


def bootstrap():
    """
    Ä°lk Ã§alÄ±ÅŸtÄ±rmada mevcut haberlerin hepsini seen'e iÅŸaretler,
    bÃ¶ylece bir anda eski yÃ¼zlerce haber Telegram'a dÃ¼ÅŸmez.
    """
    seen = load_seen()
    added = 0
    for kw in KEYWORDS:
        try:
            debug_print(f"[bootstrap] {kw!r} iÃ§in Google News RSS Ã§ekiliyor...")
            xml = google_news_rss(kw)
            for it in parse_rss(xml):
                if it["id"] not in seen:
                    seen.add(it["id"])
                    added += 1
        except Exception as e:
            debug_print("Bootstrap hata:", kw, e)

    save_seen_overwrite(seen)
    with open(INIT_FILE, "w", encoding="utf-8") as f:
        f.write(datetime.utcnow().isoformat())
    debug_print(f"âœ… Ä°lk kurulum tamam: {added} mevcut haber iÅŸaretlendi (bildirim yok).")

    # --- EK KAYNAKLAR (config.yaml) ---
    try:
        extra = gather_extra_sources()
    except Exception as e:
        notify_error(f"extra sources error: {e}")
        extra = []

    for e in extra:
        try:
            title = (e.get("title") or "").strip()
            link  = (e.get("url") or "").strip()
            # ek kaynaklarda benzersiz id:
            uid = f"{e.get('source','ext')}::{link or title}"

            # tekrar kontrolÃ¼
            if uid in seen:
                continue

            # zaman filtresi (milisaniye yoksa None gelebilir)
            pub_ts = e.get("published")
            pub_dt = datetime.utcfromtimestamp(pub_ts) if pub_ts else None
            if pub_dt is not None and pub_dt < cutoff_time:
                continue

            # domain filtresi
            if not domain_allowed(link):
                continue

            # ÅŸirket eÅŸleÅŸmesi
            item = {"title": title, "desc": "", "link": link}
            if not matches_company(item):
                # Xâ€™te @terayatirim ise doÄŸrudan kabul edelim (kurumsal hesap)
                if not (e.get("source") == "x_user" and e.get("meta", {}).get("user") == "terayatirim"):
                    continue

            # gerÃ§ekten yeni & ilgili
            new.append(("external", {
                "id": uid,
                "title": title,
                "link": link,
                "pub": "",
                "pub_dt": pub_dt,
                "desc": "",
            }))
            seen.add(uid)
            added_ids.append(uid)
        except Exception as ie:
            notify_error(f"extra item error: {ie}")



# --- ADD: google news fetcher ---
urllib.parse, feedparser

def fetch_google_news(query, lang="tr", region="TR", weight=0):
    params = {"q": query, "hl": lang, "gl": region, "ceid": f"{region}:{lang}"}
    url = "https://news.google.com/rss/search?" + urllib.parse.urlencode(params)
    feed = feedparser.parse(url)
    items = []
    for e in feed.entries:
        ts = getattr(e, "published_parsed", None)
        items.append({
            "title": e.title,
            "url": e.link,
            "published": time.mktime(ts) if ts else None,
            "source": "google_news",
            "weight": int(weight),
        })
    return items


# --- ADD: x/ nitter fetcher ---


def nitter_to_x(url: str) -> str:
    return url.replace("https://nitter.net/", "https://x.com/")

def fetch_x_user(users, nitter_base="https://nitter.net", weight=0):
    all_items = []
    headers = {"User-Agent": "Mozilla/5.0"}
    for u in users:
        rss = f"{nitter_base.rstrip('/')}/{u}/rss"
        try:
            r = requests.get(rss, timeout=12, headers=headers)
            r.raise_for_status()
        except Exception:
            continue
        feed = feedparser.parse(r.text)
        for e in feed.entries:
            ts = getattr(e, "published_parsed", None)
            all_items.append({
                "title": e.title,                # tweet metni
                "url": nitter_to_x(e.link),      # x.comâ€™a Ã§evir
                "published": time.mktime(ts) if ts else None,
                "source": "x_user",
                "weight": int(weight),
                "meta": {"user": u},
            })
    return all_items

TRIM_SEEN_KEEP = int(os.getenv("TRIM_SEEN_KEEP", "20000"))  # en yeni kaÃ§ ID kalsÄ±n
TRIM_RUN_HOUR  = os.getenv("TRIM_RUN_HOUR", "03:10")        # her gÃ¼n ÅŸu saatte Ã§alÄ±ÅŸsÄ±n (GMT+3'e gÃ¶re)

def trim_seen_file(keep: int = TRIM_SEEN_KEEP):
    """seen_ids.txt'yi budar: en yeni KEEP satÄ±rÄ± bÄ±rakÄ±r."""
    try:
        if not os.path.exists(SEEN_FILE):
            return
        with open(SEEN_FILE, "r", encoding="utf-8") as f:
            lines = [l.strip() for l in f if l.strip()]
        if len(lines) <= keep:
            debug_print(f"[trim] Gerek yok (satÄ±r={len(lines)} <= keep={keep}).")
            return
        # En sondaki satÄ±rlar en yeni eklenenler olduÄŸu iÃ§in sondan KEEP kadarÄ±nÄ± al
        new_lines = lines[-keep:]
        with open(SEEN_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(new_lines))
        debug_print(f"[trim] seen_ids.txt budandÄ±: {len(lines)} -> {len(new_lines)}")
    except Exception as e:
        notify_error(f"seen_ids.txt budanÄ±rken hata: {e}")


# =========================
# Ana iÅŸ â€” periyodik tarama
# =========================

def job():
    global LAST_JOB_TIME

    now = datetime.utcnow()
    cutoff_time = now - timedelta(hours=MAX_AGE_HOURS)

    debug_print("===== JOB BAÅLANGIÃ‡ =====", now.isoformat(), "cutoff_time:", cutoff_time.isoformat())

    seen = load_seen()
    debug_print("load_seen:", len(seen), "adet id")

    new = []

    added_ids = []  # bu run'da ilk kez gÃ¶rÃ¼len id'ler

    
    for kw in KEYWORDS:
        try:
            debug_print(f"[{kw}] Google News RSS Ã§ekiliyor...")
            xml = google_news_rss(kw)
            items = parse_rss(xml)
            debug_print(f"[{kw}] RSS item sayÄ±sÄ±:", len(items))

            for it in items:
                title = it.get("title", "").strip()
                link = it.get("link", "").strip()

                # 1) tekrar kontrolÃ¼
                if it["id"] in seen:
                    continue

                # 2) zaman filtresi
                if it["pub_dt"] is not None and it["pub_dt"] < cutoff_time:
                    # debug_print(f"[SKIP][{kw}] Eski haber:", title)
                    continue

                # 3) domain filtresi
                if not domain_allowed(link):
                    # debug_print(f"[SKIP][{kw}] Domain izinli deÄŸil: {link}")
                    continue

                # 4) ÅŸirket eÅŸleÅŸmesi
                if not matches_company(it):
                    debug_print(f"[SKIP][{kw}] Åirket eÅŸleÅŸmedi: {title}")
                    continue

                # Buraya gelmiÅŸse gerÃ§ekten TERA ile ilgili yeni haber
                new.append((kw, it))
                seen.add(it["id"])
                added_ids.append(it["id"])   # <-- EKLEDÄ°K


                added_ids.append(it["id"])      # Google News tarafÄ±nda
                # ve external blokta:
                added_ids.append(uid)           # x_user / extra kaynaklar tarafÄ±nda


        except Exception as e:
            notify_error(f"{kw!r} kelimesi taranÄ±rken hata oluÅŸtu: {e}")

    LAST_JOB_TIME = datetime.utcnow()

    if new:
        for kw, it in new:
            msg = (
                f"ğŸ“° <b>{kw.upper()}</b>\n"
                f"{it['title']}\n{it['link']}\n{it.get('pub') or ''}"
            )
            send_telegram(msg)
            save_seen_incremental(added_ids)
        debug_print(LAST_JOB_TIME, "-", len(new), "haber gÃ¶nderildi.")
    else:
        debug_print(LAST_JOB_TIME, "- Yeni haber yok.")
    debug_print("===== JOB BÄ°TTÄ° =====")


def scheduler_thread():
    """Schedule dÃ¶ngÃ¼sÃ¼nÃ¼ ayrÄ± bir thread'de Ã§alÄ±ÅŸtÄ±r."""
    # Ä°lk seferde bootstrap
    if not os.path.exists(INIT_FILE):
        bootstrap()

    # Ã‡alÄ±ÅŸÄ±r Ã§alÄ±ÅŸmaz bir defa dene
    job()

    # Sonra periyodik olarak devam et
    schedule.every(POLL_INTERVAL_MIN).minutes.do(job)

    while True:
        schedule.run_pending()
        time.sleep(1)

    # GÃ¼nlÃ¼k budama (Ã¶r. 03:10)
    schedule.every().day.at(TRIM_RUN_HOUR).do(trim_seen_file)


# --- ADD: config.yaml oku ve kaynaklarÄ± Ã§alÄ±ÅŸtÄ±r ---
import yaml, os
from urllib.parse import urlparse

def load_config():
    try:
        with open("config.yaml", "r", encoding="utf-8") as f:
            return yaml.safe_load(f) or {}
    except Exception:
        return {}

CFG = load_config()

def gather_extra_sources():
    items = []
    for src in CFG.get("sources", []):
        t = src.get("type")
        if t == "google_news":
            items.extend(fetch_google_news(
                query=src.get("query", "TERA YATIRIM"),
                lang=src.get("lang", "tr"),
                region=src.get("region", "TR"),
                weight=src.get("weight", 0),
            ))
        elif t == "x_user":
            items.extend(fetch_x_user(
                users=src.get("users", []),
                nitter_base=src.get("nitter_base", "https://nitter.net"),
                weight=src.get("weight", 0),
            ))
    return items

def job():
    global LAST_JOB_TIME
    now = datetime.utcnow()
    cutoff_time = now - timedelta(hours=MAX_AGE_HOURS)

    debug_print("===== JOB BAÅLANGIÃ‡ =====", now.isoformat(), "cutoff_time:", cutoff_time.isoformat())
    seen = load_seen()
    new = []

    # (1) Google News (anahtar kelime) taramasÄ± â€“ sizde zaten var
    for kw in KEYWORDS:
        ...
        # uygun haberleri new listesine ekleyip seenâ€™e ekliyorsunuz
        ...

    # (2) Ek kaynaklar (config.yaml: google_news / x_user)
    try:
        extra_sent = process_extra_sources(cutoff_time, seen)
    except Exception as e:
        notify_error(f"extra item error: {e}")
        extra_sent = 0

    LAST_JOB_TIME = datetime.utcnow()

    # (3) Anahtar kelime kÄ±smÄ±ndan Ã§Ä±kanlarÄ± gÃ¶nderin
    if new:
        for kw, it in new:
            msg = f"ğŸ“° <b>{kw.upper()}</b>\n{it['title']}\n{it['link']}\n{it.get('pub') or ''}"
            send_telegram(msg)

    # (4) seenâ€™i bir kere kaydedin
    save_seen(seen)

    sent_total = (len(new) if new else 0) + extra_sent
    if sent_total > 0:
        debug_print(LAST_JOB_TIME, "-", sent_total, "haber gÃ¶nderildi.")
    else:
        debug_print(LAST_JOB_TIME, "- Yeni haber yok.")
    debug_print("===== JOB BÄ°TTÄ° =====")


# =========================
# Flask (health / test)
# =========================

app = Flask(__name__)


@app.get("/")
def home():
    return "Alive", 200


@app.get("/health")
def health():
    now = datetime.utcnow()

    if LAST_JOB_TIME is None:
        last_job_iso = None
        last_job_ago_sec = None
    else:
        last_job_iso = LAST_JOB_TIME.isoformat()
        last_job_ago_sec = (now - LAST_JOB_TIME).total_seconds()

    return jsonify(
        ok=True,
        time=now.isoformat(),
        last_job=last_job_iso,
        last_job_ago_seconds=last_job_ago_sec,
    ), 200


@app.get("/test")
def test_notification():
    """
    /test?msg=...  -> Telegram'a serbest mesaj yollar.
    parametre verilmezse varsayÄ±lan kÄ±sa test mesajÄ± atar.
    """
    msg = request.args.get("msg", "").strip()
    if not msg:
        msg = "ğŸ§ª Test bildirimi: sistem Ã§alÄ±ÅŸÄ±yor."
    send_telegram(msg)
    return f"Test bildirimi gÃ¶nderildi: {msg}", 200


@app.get("/restart")
def restart():
    """
    Self-restart endpoint:
    - Cron-job burayÄ± Ã§aÄŸÄ±rÄ±nca
    - Uygulama 2 saniye sonra kendini kapatÄ±r
    - Render otomatik olarak yeniden ayaÄŸa kaldÄ±rÄ±r
    """

    # Ä°steÄŸe baÄŸlÄ± gÃ¼venlik: RESTART_TOKEN tanÄ±mlÄ±ysa, token=... ile gelmeyenleri reddet
    env_token = os.getenv("RESTART_TOKEN", "").strip()
    req_token = (request.args.get("token") or "").strip()

    if env_token:
        if req_token != env_token:
            return jsonify({"ok": False, "error": "unauthorized"}), 403

    debug_print("â™»ï¸ Self-restart istendi, 2 saniye iÃ§inde Ã§Ä±kÄ±ÅŸ yapÄ±lacak...")

    def _do_exit():
        time.sleep(2)
        debug_print("Self-restart: process sonlandÄ±rÄ±lÄ±yor (Render yeniden baÅŸlatacak).")
        os._exit(0)

    threading.Thread(target=_do_exit, daemon=True).start()

    return jsonify({"ok": True, "message": "restart scheduled"}), 200




# =========================
# Entry point
# =========================

def main():
    # Haber tarama iÅŸini ayrÄ± thread'de baÅŸlat
    threading.Thread(target=scheduler_thread, daemon=True).start()

    # Flask web server â€” Render PORT deÄŸiÅŸkenini kullan
    port = int(os.environ.get("PORT", "10000"))
    debug_print(f"ğŸŒ Flask baÅŸlÄ±yor, port={port}")
    app.run(host="0.0.0.0", port=port)


if __name__ == "__main__":
    main()
