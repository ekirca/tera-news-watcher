# -*- coding: utf-8 -*-
"""
Tera News Watcher ‚Äî Render temiz s√ºr√ºm
- Google News (RSS) + Opsiyonel extra kaynaklar (config.yaml)
- ≈ûirket e≈üle≈ümesi, domain beyaz liste, ya≈ü filtresi, tekrar filtresi
- Telegram g√∂nderimi
- /health, /test, /restart (cron i√ßin) endpoint'leri
"""

import os
import time
import threading
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus, urlparse

import requests
from flask import Flask, jsonify, request
import schedule
import xml.etree.ElementTree as ET
from email.utils import parsedate_to_datetime

# ---- Opsiyonel kaynaklar ----
import feedparser
import yaml

# =========================
# Ortam deƒüi≈ükenleri
# =========================
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
TELEGRAM_CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID", "").strip()

POLL_INTERVAL_MIN  = int(os.getenv("POLL_INTERVAL_MIN", "10"))
MAX_AGE_HOURS      = int(os.getenv("MAX_AGE_HOURS", "72"))

# Domain filtresini komple kapatmak istersen "true" yap
DISABLE_DOMAIN_FILTER = os.getenv("DISABLE_DOMAIN_FILTER", "false").lower() == "false"

# Restart g√ºvenliƒüi (opsiyonel)
RESTART_TOKEN = os.getenv("RESTART_TOKEN", "").strip()

# =========================
# Dosyalar
# =========================
SEEN_FILE = "seen_ids.txt"
INIT_FILE = ".initialized"
MAX_SEEN_IDS = 50000  # maksimum satƒ±r sayƒ±sƒ±

# =========================
# Anahtar kelimeler & ≈ûirket e≈üle≈ümesi
# =========================
KEYWORDS = [
    "tera", "tera yatƒ±rƒ±m", "tera yatirim",
    "tehol", "trhol", "tly", "tera ≈üirketleri",
]

COMPANY_TOKENS = [
    # Holding / ana
    "tera yatƒ±rƒ±m", "tera yatƒ±rƒ±m menkul deƒüerler", "tera yatƒ±rƒ±m menkul degerler",
    "tera yatƒ±rƒ±m menkul deƒüerler a.≈ü", "tera yatƒ±rƒ±m menkul degerler a.s",
    # Finans
    "tera bank", "tera finans faktoring", "tera portf√∂y", "tera giri≈üim sermayesi",
    "kointra", "tera finansal yatƒ±rƒ±mlar holding",
    # Teknoloji
    "tera yatƒ±rƒ±m teknoloji holding", "barikat grup", "barikat",
    "tra bili≈üim", "tra bilisim",
    # Tarƒ±m / Su
    "viva terra hayvancƒ±lƒ±k", "viva terra su",
    # Hizmet
    "tera √∂zel g√ºvenlik",
    # Fon/√ºr√ºn
    "tly fonu", "tera ly", "tera ly fonu",
]

BASE_KEYWORDS = [
    "tera", "tera yatirim", "tera yatƒ±rƒ±m", "tera yatƒ±rƒ±m menkul",
    "tera yatƒ±rƒ±m menkul deƒüerler", "tera yatƒ±rƒ±m teknoloji holding",
    "tera finansal yatƒ±rƒ±mlar holding", "barikat", "tra bilisim",
    "tra bili≈üim", "viva terra",
]

# Default domain beyaz liste (config.yaml ile birle≈üecek)
DEFAULT_ALLOWED_DOMAINS = [
    # b√ºy√ºk haber
    "hurriyet.com.tr", "milliyet.com.tr", "cnnturk.com", "ntv.com.tr",
    "bbc.com", "reuters.com", "bloomberg.com", "bloomberght.com",
    "aa.com.tr", "trthaber.com", "aljazeera.com",
    # ekonomi/finans
    "dunya.com", "ekonomim.com", "foreks.com", "investing.com",
    "ekoturk.com", "haberturk.com", "sozcu.com.tr", "sabah.com.tr",
    "t24.com.tr", "patronlardunyasi.com", "borsagundem.com.tr",
    "finansgundem.com", "bigpara.hurriyet.com.tr", "tr.investing.com",
    # resmi/kurumsal
    "kap.org.tr", "kamuyuaydinlatma.com",
]

# =========================
# Global durum / yardƒ±mcƒ±lar
# =========================
LAST_JOB_TIME  = None
LAST_ERROR_TIME = None
ERROR_COOLDOWN_MIN = 30

app = Flask(__name__)

def debug(*a):
    print(*a, flush=True)

def normalize_text(s: str) -> str:
    table = str.maketrans("√á√ßƒûƒüƒ∞Iƒ±√ñ√∂≈û≈ü√ú√º", "ccggiiioossuu")
    return (s or "").translate(table).lower()

def matches_company(item: dict) -> bool:
    text = normalize_text((item.get("title","") + " " + item.get("desc","")))
    tokens = [normalize_text(k) for k in (COMPANY_TOKENS + BASE_KEYWORDS)]
    return any(tok in text for tok in tokens)

def send_telegram(text: str):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        debug("‚ö†Ô∏è TELEGRAM_BOT_TOKEN/CHAT_ID yok; mesaj atƒ±lmadƒ±.")
        return
    try:
        u = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        r = requests.post(u, data={"chat_id": TELEGRAM_CHAT_ID, "text": text, "parse_mode":"HTML"}, timeout=15)
        debug("Telegram status:", r.status_code)
    except Exception as e:
        debug("Telegram error:", e)

def notify_error(msg: str):
    global LAST_ERROR_TIME
    now = datetime.now(timezone.utc)
    if LAST_ERROR_TIME is None or (now - LAST_ERROR_TIME).total_seconds() > ERROR_COOLDOWN_MIN*60:
        send_telegram(f"‚ö†Ô∏è Hata uyarƒ±sƒ±:\n{msg}")
        LAST_ERROR_TIME = now
    debug("ERROR:", msg)

def load_config() -> dict:
    try:
        with open("config.yaml","r",encoding="utf-8") as f:
            return yaml.safe_load(f) or {}
    except Exception:
        return {}

CFG = load_config()
ALLOWED_DOMAINS = list(dict.fromkeys(DEFAULT_ALLOWED_DOMAINS + [  # uniq + preserve order
    *(CFG.get("domains_allow") or [])
]))

def domain_allowed(link: str) -> bool:
    if DISABLE_DOMAIN_FILTER:
        return True
    try:
        netloc = urlparse(link).netloc.lower()
        if netloc.startswith("www."):
            netloc = netloc[4:]
        return any(netloc.endswith(d) for d in ALLOWED_DOMAINS)
    except Exception:
        return False

# =============== seen (sƒ±ralƒ± + hƒ±zlƒ±) ===============
def load_seen():
    if not os.path.exists(SEEN_FILE):
        return [], set()
    with open(SEEN_FILE, "r", encoding="utf-8") as f:
        lines = [ln.strip() for ln in f if ln.strip()]
    return lines, set(lines)

def save_seen(seen_list):
    # Liste √ßok uzunsa sondan MAX_SEEN_IDS bƒ±rak
    if len(seen_list) > MAX_SEEN_IDS:
        seen_list = seen_list[-MAX_SEEN_IDS:]
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(seen_list))

# =============== RSS (Google News) ===============
def google_news_rss(query: str) -> str:
    q = quote_plus(query + " site:tr OR site:.com OR site:.com.tr")
    u = f"https://news.google.com/rss/search?q={q}&hl=tr&gl=TR&ceid=TR:tr"
    r = requests.get(u, timeout=30)
    r.raise_for_status()
    return r.text

def parse_rss(xml_text: str):
    root = ET.fromstring(xml_text)
    items = []
    for it in root.findall(".//item"):
        title = (it.findtext("title") or "").strip()
        link  = (it.findtext("link") or "").strip()
        guid  = (it.findtext("guid") or link or title).strip()
        pub   = (it.findtext("pubDate") or "").strip()
        desc  = (it.findtext("description") or "").strip()

        pub_dt = None
        if pub:
            try:
                dt = parsedate_to_datetime(pub)
                # aware -> UTC aware
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=timezone.utc)
                else:
                    dt = dt.astimezone(timezone.utc)
                pub_dt = dt
            except Exception:
                pub_dt = None

        items.append({"id": guid or link or title, "title": title, "link": link, "pub": pub, "pub_dt": pub_dt, "desc": desc})
    return items

# =============== EXTRA SOURCES (config.yaml) ===============
def fetch_google_news_feed(query, lang="tr", region="TR", weight=0):
    params = {"q": query, "hl": lang, "gl": region, "ceid": f"{region}:{lang}"}
    url = "https://news.google.com/rss/search?" + requests.compat.urlencode(params)
    feed = feedparser.parse(url)
    out = []
    for e in feed.entries:
        ts = getattr(e, "published_parsed", None)
        published = datetime.fromtimestamp(time.mktime(ts), tz=timezone.utc) if ts else None
        out.append({
            "id": e.get("id") or e.get("link") or e.get("title"),
            "title": e.get("title",""),
            "link": e.get("link",""),
            "pub_dt": published,
            "desc": "",
            "weight": int(weight),
            "source": "google_news",
        })
    return out

def nitter_to_x(url: str) -> str:
    return url.replace("https://nitter.net/", "https://x.com/")

def fetch_x_user(users, nitter_base="https://nitter.net", weight=0):
    all_items = []
    headers = {"User-Agent": "Mozilla/5.0"}
    for u in users or []:
        rss = f"{nitter_base.rstrip('/')}/{u}/rss"
        try:
            r = requests.get(rss, timeout=15, headers=headers)
            r.raise_for_status()
            feed = feedparser.parse(r.text)
        except Exception:
            continue
        for e in feed.entries:
            ts = getattr(e, "published_parsed", None)
            published = datetime.fromtimestamp(time.mktime(ts), tz=timezone.utc) if ts else None
            all_items.append({
                "id": e.get("id") or e.get("link") or e.get("title"),
                "title": e.get("title",""),
                "link": nitter_to_x(e.get("link","")),
                "pub_dt": published,
                "desc": "",
                "weight": int(weight),
                "source": "x_user",
            })
    return all_items

def gather_extra_sources():
    items = []
    for src in (CFG.get("sources") or []):
        t = src.get("type")
        if t == "google_news":
            items.extend(fetch_google_news_feed(
                query = src.get("query","TERA YATIRIM"),
                lang  = src.get("lang","tr"),
                region= src.get("region","TR"),
                weight= src.get("weight",0),
            ))
        elif t == "x_user":
            items.extend(fetch_x_user(
                users = src.get("users", []),
                nitter_base = src.get("nitter_base","https://nitter.net"),
                weight = src.get("weight",0),
            ))
    return items

# =============== Bootstrap ===============
def bootstrap():
    seen_list, _ = load_seen()
    added = 0
    # mevcut RSS anahtar kelimeleri
    for kw in KEYWORDS:
        try:
            xml = google_news_rss(kw)
            for it in parse_rss(xml):
                if it["id"] not in seen_list:
                    seen_list.append(it["id"]); added += 1
        except Exception as e:
            debug("bootstrap err (kw):", kw, e)
    # config'teki extra kaynaklar
    try:
        for it in gather_extra_sources():
            if it["id"] not in seen_list:
                seen_list.append(it["id"]); added += 1
    except Exception as e:
        debug("bootstrap err (extra):", e)

    save_seen(seen_list)
    with open(INIT_FILE, "w", encoding="utf-8") as f:
        f.write(datetime.now(timezone.utc).isoformat())
    debug(f"‚úÖ ƒ∞lk kurulum tamam: {added} mevcut haber i≈üaretlendi.")

# =============== ƒ∞≈ü (job) ===============
def job():
    global LAST_JOB_TIME

    now_utc = datetime.now(timezone.utc)
    cutoff_time = now_utc - timedelta(hours=MAX_AGE_HOURS)

    debug("===== JOB BA≈ûLANGI√á =====", now_utc.isoformat(), "cutoff_time:", cutoff_time.isoformat())

    seen_list, seen_set = load_seen()
    new_items = []

    # 1) Google News (kelime bazlƒ±)
    for kw in KEYWORDS:
        try:
            debug(f"[{kw}] Google News RSS √ßekiliyor...")
            xml = google_news_rss(kw)
            items = parse_rss(xml)
            debug(f"[{kw}] RSS item sayƒ±sƒ±:", len(items))
            for it in items:
                if it["id"] in seen_set:
                    continue
                if it["pub_dt"] and it["pub_dt"] < cutoff_time:
                    continue
                if not domain_allowed(it["link"]):
                    continue
                if not matches_company(it):
                    continue
                new_items.append(("KW", kw, it))
                seen_set.add(it["id"]); seen_list.append(it["id"])
        except Exception as e:
            notify_error(f"{kw!r} kelimesi taranƒ±rken hata: {e}")

    # 2) Extra sources (config.yaml)
    try:
        extra = gather_extra_sources()
        for it in extra:
            try:
                if it["id"] in seen_set:
                    continue
                if it.get("pub_dt") and it["pub_dt"] < cutoff_time:
                    continue
                if it.get("link") and not domain_allowed(it["link"]):
                    continue
                # Extra kaynaklarda ≈üirket e≈üle≈ümesini yine uygulayalƒ±m
                if not matches_company(it):
                    continue
                new_items.append((it.get("source","EXT"), "", it))
                seen_set.add(it["id"]); seen_list.append(it["id"])
            except Exception as ee:
                notify_error(f"extra item error: {ee}")
    except Exception as e:
        notify_error(f"extra sources error: {e}")

    # sonu√ß
    LAST_JOB_TIME = datetime.now(timezone.utc)

    if new_items:
        for src, kw, it in new_items:
            head = kw.upper() if kw else src.upper()
            pub_str = it.get("pub") or (it.get("pub_dt").isoformat() if it.get("pub_dt") else "")
            msg = f"üì∞ <b>{head}</b>\n{it.get('title','')}\n{it.get('link','')}\n{pub_str}"
            send_telegram(msg)
        save_seen(seen_list)
        debug(LAST_JOB_TIME, "-", len(new_items), "haber g√∂nderildi.")
    else:
        debug(LAST_JOB_TIME, "- Yeni haber yok.")
    debug("===== JOB Bƒ∞TTƒ∞ =====")

def scheduler_thread():
    if not os.path.exists(INIT_FILE):
        bootstrap()

    # hemen bir kez √ßalƒ±≈ütƒ±r
    job()
    # sonra periyodik
    schedule.every(POLL_INTERVAL_MIN).minutes.do(job)
    while True:
        schedule.run_pending()
        time.sleep(1)

# =============== Flask endpoints ===============
@app.get("/")
def home():
    return "Alive", 200

@app.get("/health")
def health():
    now = datetime.now(timezone.utc)
    if LAST_JOB_TIME is None:
        ago = None
        last_iso = None
    else:
        ago = (now - LAST_JOB_TIME).total_seconds()
        last_iso = LAST_JOB_TIME.isoformat()
    return jsonify(ok=True, time=now.isoformat(), last_job=last_iso, last_job_ago_seconds=ago), 200

@app.get("/test")
def test_notification():
    send_telegram("üß™ Test bildirimi: TERA test haberi bulundu!")
    return "Test bildirimi g√∂nderildi.", 200

@app.get("/restart")
def restart():
    if RESTART_TOKEN:
        if (request.args.get("token","").strip() != RESTART_TOKEN):
            return jsonify({"ok": False, "error":"unauthorized"}), 403

    debug("‚ôªÔ∏è Self-restart istendi; 2 sn sonra √ßƒ±kƒ±lacak‚Ä¶")
    def _do_exit():
        time.sleep(2)
        debug("Self-restart: process sonlandƒ±rƒ±lƒ±yor.")
        os._exit(0)
    threading.Thread(target=_do_exit, daemon=True).start()
    return jsonify({"ok": True, "message":"restart scheduled"}), 200

# =============== Entry ===============
def main():
    threading.Thread(target=scheduler_thread, daemon=True).start()
    port = int(os.environ.get("PORT","10000"))
    debug(f"üåê Flask ba≈ülƒ±yor, port={port}")
    app.run(host="0.0.0.0", port=port)

if __name__ == "__main__":
    main()
